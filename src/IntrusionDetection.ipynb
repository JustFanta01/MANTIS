{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import closing, square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Video FPS: 12\n",
      "[I] Video Length: 41.916666666666664\n",
      "[I] Video Frame Width: 320\n",
      "[I] Video Frame height: 240\n"
     ]
    }
   ],
   "source": [
    "video_path = \"../video/rilevamento-intrusioni-video.wm\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "assert cap.isOpened(), \"Not opened!\"\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "length = cap.get(cv2.CAP_PROP_FRAME_COUNT) / fps\n",
    "\n",
    "print(f\"[I] Video FPS: {fps}\")\n",
    "print(f\"[I] Video Length: {length}\")\n",
    "\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(f\"[I] Video Frame Width: {width}\")\n",
    "print(f\"[I] Video Frame height: {height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOG2 Background Subtractor\n",
    "mog2 = cv2.createBackgroundSubtractorMOG2(history=fps * 2, varThreshold=20, detectShadows=False)\n",
    "#mog2.setNMixtures(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#     Performed a sorted insertion of pv into the frame buffer in the pi row.\n",
    "#     pv: pixel value\n",
    "#     pi: pixel index\n",
    "#     frame_buffer (global)\n",
    "# \"\"\"\n",
    "# def sortAndInsert(pv, pi, ):\n",
    "#     global frame_buffer\n",
    "#     insertion_idx = np.searchsorted(frame_buffer[pi], pv)\n",
    "#     if insertion_idx == len(frame_buffer[pi]):\n",
    "#         insertion_idx =- 1\n",
    "\n",
    "#     frame_buffer[pi, insertion_idx] = pv\n",
    "\n",
    "#cv2.imshow(\"frame_copy\", frame_contours)\n",
    "# largestContour = max(contours, key = cv2.contourArea) # get largest contour\n",
    "# rect = cv2.minAreaRect(largestContour)\n",
    "# box = np.int64(cv2.boxPoints(rect))\n",
    "# cv2.drawContours(frame_contours, [box], 0, (0,0,255), 1)\n",
    "# cv2.imshow(\"frame_contours\", frame_contours)\n",
    "\n",
    "# cv2.imshow(f\"temporalMedianBackground-frame-{frame_count}\", temporalMedianBackground)\n",
    "# cmd = cv2.waitKey(0)\n",
    "# cv2.destroyWindow(f\"temporalMedianBackground-frame-{frame_count}\")\n",
    "# if cmd == ord(\"q\"):\n",
    "#     break\n",
    "# if cmd == ord(\"n\"):\n",
    "#     continue\n",
    "\n",
    "# alpha = 3.0 # Contrast control\n",
    "# beta = 25 # Brightness control\n",
    "# # call convertScaleAbs function\n",
    "# #adjusted = cv2.convertScaleAbs(mog2_fgmask, alpha=alpha, beta=beta)\n",
    "\n",
    "\n",
    "# plt.hist(frame_diff.ravel(), 256, [0, 256])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "            \n",
    "# Disegna la bounding box\n",
    "#cv2.rectangle(frame_contours, (x_min, y_min), (x_max, y_max), 255, 2)\n",
    "\n",
    "#cv2.imshow(\"frame_contours\", frame_contours)\n",
    "\n",
    "\n",
    "# analysis = cv2.connectedComponentsWithStats(tmb_fgmask, 8, cv2.CV_32S)\n",
    "# (totalLabels, label_ids, values, centroid) = analysis \n",
    "\n",
    "# # Initialize a new image to store  \n",
    "# # all the output components \n",
    "# output = np.zeros(tmb_fgmask.shape, dtype=\"uint8\") \n",
    "\n",
    "# # Loop through each component \n",
    "# for i in range(1, totalLabels): \n",
    "    \n",
    "#     # Area of the component \n",
    "#     area = values[i, cv2.CC_STAT_AREA]  \n",
    "    \n",
    "#     if (area > 140) and (area < 400): \n",
    "#         componentMask = (label_ids == i).astype(\"uint8\") * 255\n",
    "#         output = cv2.bitwise_or(output, componentMask) \n",
    "\n",
    "# cv2.imshow(\"Filtered Components\", output) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(frame):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply Median Blur\n",
    "    median = cv2.medianBlur(gray, 3)\n",
    "    gaussian = cv2.GaussianBlur(median, (3, 3), 0)\n",
    "    return gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up the window for fullscreen display\n",
    "# window_name = \"Fullscreen Quad View\"\n",
    "# cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "# cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19762/3159033442.py:37: FutureWarning: `square` is deprecated since version 0.25 and will be removed in version 0.27. Use `skimage.morphology.footprint_rectangle` instead.\n",
      "  bw = closing(blur >= thresh, square(7))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Released Video Resource\n",
      "[I] Elapsed time: 32.64481735229492 s\n"
     ]
    }
   ],
   "source": [
    "# HYPERPARAMTERS\n",
    "MAX_HISTORY = 4 * fps\n",
    "SKIP_FRAMES = fps // 2\n",
    "THRESHOLD = 25\n",
    "\n",
    "# 320x240 rows, 60 columns\n",
    "# frame_buffer = np.empty((width * height,MAX_HISTORY), dtype=np.uint8)\n",
    "\n",
    "start = time.time()\n",
    "frames = []\n",
    "initialized = False\n",
    "frame_count = 0\n",
    "skip_count = 0\n",
    "fgmask_diff = None\n",
    "temporalMedianBackground = None\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame_original = cap.read()\n",
    "    if not ret or frame_original is None:\n",
    "        cap.release()\n",
    "        print(\"Released Video Resource\")\n",
    "        break\n",
    "\n",
    "    frame = preprocessing(frame_original)\n",
    "    frame_count += 1\n",
    "    skip_count += 1\n",
    "\n",
    "    mog2_fgmask = mog2.apply(frame)\n",
    "    #mog2_fgmask = cv2.erode(mog2_fgmask,  np.ones((3, 3), np.uint8), iterations=1)\n",
    "    mog2_fgmask = cv2.medianBlur(mog2_fgmask, 3)\n",
    "    #cv2.imshow(\"Mog2 foreground mask\", mog2_fgmask)\n",
    "\n",
    "    # # tentativo\n",
    "    blur = cv2.GaussianBlur(mog2_fgmask, (5,5), 0)\n",
    "    thresh = threshold_otsu(blur)\n",
    "    if thresh > 0:    \n",
    "        bw = closing(blur >= thresh, square(7))\n",
    "        erode = cv2.medianBlur(bw.astype(np.uint8) * 255, 3)\n",
    "        dilated = cv2.dilate(erode, None, iterations=5)\n",
    "\n",
    "        frame_contours = frame.copy()\n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        real_countours = []\n",
    "        for contour in contours:\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            \n",
    "            if cv2.contourArea(contour) > 100:\n",
    "                real_countours.append(contour)\n",
    "            \n",
    "        # evitare che impazzisca se non ci sono bboxes\n",
    "        if len(real_countours) > 0:\n",
    "            # Calcola la bounding box\n",
    "            # Define the ROI            \n",
    "            x_min = min([np.min(cnt[:, :, 0]) for cnt in real_countours])\n",
    "            x_max = max([np.max(cnt[:, :, 0]) for cnt in real_countours])\n",
    "            y_min = min([np.min(cnt[:, :, 1]) for cnt in real_countours])\n",
    "            y_max = max([np.max(cnt[:, :, 1]) for cnt in real_countours])\n",
    "\n",
    "    if initialized:\n",
    "        # print(f\"[I] Skipping Frames... {skip_count}\")\n",
    "        if skip_count > SKIP_FRAMES:\n",
    "            skip_count = 0\n",
    "            frames.pop(0)\n",
    "            frames.append(frame)\n",
    "            # print(f\"[I] Added Image...\")\n",
    "\n",
    "            temporalMedianBackground = np.median(frames, axis=0).astype(dtype=np.uint8)\n",
    "            \n",
    "    if not initialized and len(frames) < MAX_HISTORY:\n",
    "        # print(f\"[I] Learning...\")\n",
    "        frames.append(frame)\n",
    "        \n",
    "    elif not initialized and len(frames) == MAX_HISTORY:\n",
    "        # print(f\"Compute First Estimate\")\n",
    "        # compute the first background estimation\n",
    "        initialized = True    \n",
    "        temporalMedianBackground = np.median(frames, axis=0).astype(dtype=np.uint8)\n",
    "\n",
    "    # Compute the AbsDiff between temporalMedianBackground and the Current Frame\n",
    "    if initialized:\n",
    "        frame_diff = cv2.absdiff(temporalMedianBackground, frame)\n",
    "        threshold, tmb_fgmask = cv2.threshold(frame_diff, THRESHOLD, 255, cv2.THRESH_BINARY)       # cv2.adaptiveThreshold\n",
    "        \n",
    "        # logical or between mog2 and temporalMedianBackground to create the shape of the fast movement using ROI\n",
    "        fgmask = mog2_fgmask.copy()\n",
    "        fgmask[y_min:y_max, x_min:x_max] = cv2.bitwise_or(mog2_fgmask[y_min:y_max, x_min:x_max], tmb_fgmask[y_min:y_max, x_min:x_max])    \n",
    "        #cv2.imshow(\"Bitwise Mask\", fgmask)\n",
    "        \n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        closing_img = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "        #cv2.imshow(\"closing\", closing_img)\n",
    "\n",
    "        # override frozen values\n",
    "        if fgmask_diff is not None:\n",
    "            tmb_fgmask = cv2.bitwise_or(tmb_fgmask, fgmask_diff)\n",
    "            cv2.imshow(\"tmb_fgmask\", tmb_fgmask)\n",
    "            # TODO: contours and areas\n",
    "\n",
    "        # static objects\n",
    "        fgmask_diff = cv2.bitwise_and(tmb_fgmask, cv2.bitwise_not(closing_img))\n",
    "        #cv2.imshow(\"fgmask_diff\", fgmask_diff)\n",
    "\n",
    "        cmd = cv2.waitKey(0)\n",
    "        if cmd == ord(\"q\"):\n",
    "            break\n",
    "        if cmd == ord(\"n\"):\n",
    "            continue\n",
    "        \n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"[I] Elapsed time: {end - start} s\")\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computervision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
