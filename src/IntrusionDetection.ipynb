{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import closing, square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"../video/rilevamento-intrusioni-video.wm\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "assert cap.isOpened(), \"Not opened!\"\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "total_frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "length = total_frame_count / fps\n",
    "\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(f\"[I] Video FPS: {fps}\")\n",
    "print(f\"[I] Video Total frame count: {total_frame_count}\")\n",
    "print(f\"[I] Video Length: {length}\")\n",
    "print(f\"[I] Video Frame Width: {width}\")\n",
    "print(f\"[I] Video Frame height: {height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to understand MOG2 parameters\n",
    "\n",
    "# # BackgroundRatio --> ok default (0.9) per ora quindi\n",
    "# If a foreground pixel keeps semi-constant value for about backgroundRatio*history frames, it's considered background and added to the model \n",
    "# as a center of a new component.\n",
    "# \"In altre parole, TB controlla quanto velocemente il modello di sfondo si adatta ai cambiamenti nella scena.\"\n",
    "# - Un valore più alto rende il modello di sfondo più adattabile e meno sensibile ai movimenti.\n",
    "# - Un valore più basso rende il modello di sfondo più stabile e più sensibile ai movimenti, ma anche più lento ad adattarsi.\n",
    "\n",
    "# # VarThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOG2 Background Subtractor\n",
    "mog2 = cv2.createBackgroundSubtractorMOG2()\n",
    "mog2_test = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "mog2.setHistory(fps*6)\n",
    "mog2.setDetectShadows(False)\n",
    "mog2.setVarThreshold(9)\n",
    "mog2.setBackgroundRatio(0.6)\n",
    "\n",
    "mog2_test.setHistory(fps)\n",
    "mog2_test.setDetectShadows(False)\n",
    "mog2_test.setVarThreshold(9)\n",
    "mog2_test.setBackgroundRatio(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#     Performed a sorted insertion of pv into the frame buffer in the pi row.\n",
    "#     pv: pixel value\n",
    "#     pi: pixel index\n",
    "#     frame_buffer (global)\n",
    "# \"\"\"\n",
    "# def sortAndInsert(pv, pi, ):\n",
    "#     global frame_buffer\n",
    "#     insertion_idx = np.searchsorted(frame_buffer[pi], pv)\n",
    "#     if insertion_idx == len(frame_buffer[pi]):\n",
    "#         insertion_idx =- 1\n",
    "\n",
    "#     frame_buffer[pi, insertion_idx] = pv\n",
    "\n",
    "#cv2.imshow(\"frame_copy\", frame_contours)\n",
    "# largestContour = max(contours, key = cv2.contourArea) # get largest contour\n",
    "# rect = cv2.minAreaRect(largestContour)\n",
    "# box = np.int64(cv2.boxPoints(rect))\n",
    "# cv2.drawContours(frame_contours, [box], 0, (0,0,255), 1)\n",
    "# cv2.imshow(\"frame_contours\", frame_contours)\n",
    "\n",
    "# cv2.imshow(f\"temporalMedianBackground-frame-{frame_count}\", temporalMedianBackground)\n",
    "# cmd = cv2.waitKey(0)\n",
    "# cv2.destroyWindow(f\"temporalMedianBackground-frame-{frame_count}\")\n",
    "# if cmd == ord(\"q\"):\n",
    "#     break\n",
    "# if cmd == ord(\"n\"):\n",
    "#     continue\n",
    "\n",
    "# alpha = 3.0 # Contrast control\n",
    "# beta = 25 # Brightness control\n",
    "# # call convertScaleAbs function\n",
    "# #adjusted = cv2.convertScaleAbs(mog2_fgmask, alpha=alpha, beta=beta)\n",
    "\n",
    "\n",
    "# plt.hist(frame_diff.ravel(), 256, [0, 256])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "            \n",
    "# Disegna la bounding box\n",
    "#cv2.rectangle(frame_contours, (x_min, y_min), (x_max, y_max), 255, 2)\n",
    "\n",
    "#cv2.imshow(\"frame_contours\", frame_contours)\n",
    "\n",
    "\n",
    "# analysis = cv2.connectedComponentsWithStats(tmb_fgmask, 8, cv2.CV_32S)\n",
    "# (totalLabels, label_ids, values, centroid) = analysis \n",
    "\n",
    "# # Initialize a new image to store  \n",
    "# # all the output components \n",
    "# output = np.zeros(tmb_fgmask.shape, dtype=\"uint8\") \n",
    "\n",
    "# # Loop through each component \n",
    "# for i in range(1, totalLabels): \n",
    "    \n",
    "#     # Area of the component \n",
    "#     area = values[i, cv2.CC_STAT_AREA]  \n",
    "    \n",
    "#     if (area > 140) and (area < 400): \n",
    "#         componentMask = (label_ids == i).astype(\"uint8\") * 255\n",
    "#         output = cv2.bitwise_or(output, componentMask) \n",
    "\n",
    "# cv2.imshow(\"Filtered Components\", output)\n",
    "# \n",
    "# \n",
    "#mog2 = cv2.createBackgroundSubtractorMOG2(history=fps*2, varThreshold=20, detectShadows=False)\n",
    "\n",
    "# print(mog2.getHistory())\n",
    "# print(mog2.getVarThreshold())\n",
    "# print(mog2.getBackgroundRatio())\n",
    "# print(mog2.getNMixtures())\n",
    "# print(mog2.getVarThresholdGen())\n",
    "# print(mog2.getVarMin())\n",
    "# print(mog2.getVarMax())\n",
    "# print(mog2.getComplexityReductionThreshold())\n",
    "# print(mog2.getVarInit())\n",
    "\n",
    "#mog2.setComplexityReductionThreshold(0)\n",
    "#mog2.setBackgroundRatio(0.7)\n",
    "#mog2.setNMixtures(1)\n",
    "#mog2.setVarThresholdGen(30) \n",
    "\n",
    "#temporalMedianBackground_tmp = np.median(frames_tmp, axis=0).astype(dtype=np.uint8)\n",
    "#cv2.imshow(\"temporal background - true one\", temporalMedianBackground)\n",
    "# make addWeighted between temporalMedianBackground and frame just where the background_mask is 1\n",
    "#masked_img = np.where(background_mask[..., None] == 255, frame[..., None], 0) # dove c'è il background mask metti frame, altrimenti 0\n",
    "#cv2.imshow(\"masked_img\", masked_img)\n",
    "#temporalMedianBackground = cv2.addWeighted(temporalMedianBackground, 0.7, masked_img, 0.3, 0)\n",
    "#temporalMedianBackground = cv2.bitwise_and(temporalMedianBackground, temporalMedianBackground, background_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(frame):\n",
    "    \"\"\"\n",
    "        Apply all the preprocessing steps to a copy of the passed frame.\n",
    "\n",
    "        Arguments:\n",
    "            frame (MatLike): frame to process\n",
    "\n",
    "        Returns:\n",
    "            (MatLike): a processed copy of the frame\n",
    "    \"\"\"\n",
    "\n",
    "    output = frame.copy()\n",
    "    # Convert to grayscale\n",
    "    output = cv2.cvtColor(output, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Median Blur\n",
    "    output = cv2.medianBlur(output, 5)\n",
    "    output = cv2.GaussianBlur(output, (7, 7), 3)\n",
    "\n",
    "    # Apply Bilateral Filter\n",
    "    output = cv2.bilateralFilter(output, 9, 75, 75)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLearningRate(frame_count, history_length, dynamic, bias = 0):\n",
    "    \"\"\"\n",
    "        Computes the learning rate\n",
    "\n",
    "        Arguments:\n",
    "            frame_count (int) : current frame number\n",
    "            history_lenght (int): number of frames in buffer\n",
    "            dynamic (boolean)\n",
    "            bias (float): constant added to the computed learning rate\n",
    "\n",
    "        Returns:\n",
    "            float: the learning rate to use\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    assert frame_count > 0, \"Frame Count must be greater than zero\"\n",
    "    if dynamic and frame_count < history_length:\n",
    "        return (1 / frame_count) + bias\n",
    "    \n",
    "    return (1 / history_length) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(fgmask, kernel = None):\n",
    "    \"\"\"\n",
    "        Apply a pipeline of morphological operators to improve the segmentation\n",
    "\n",
    "        Arguments:\n",
    "            fgmask (Frame): a binary image\n",
    "            kernel (Mat): kernel used by the morph operators\n",
    "\n",
    "        Returns:\n",
    "            fgmask: a processed copy of the input image\n",
    "    \"\"\"\n",
    "    output = fgmask.copy()\n",
    "    output = cv2.erode(output, None, iterations=1)\n",
    "    output = cv2.dilate(output, None, iterations=3)\n",
    "    output = cv2.morphologyEx(output, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backgroundSubtraction(frame, background, threshold=25, C=None):\n",
    "    \"\"\"\n",
    "        Computes the absolute difference between the frame and the background then applies a threshold to segment the\n",
    "        background and the foreground.\n",
    "\n",
    "        Arguments:\n",
    "            frame (Mat): image, current frame\n",
    "            background (Mat): image, estimated reference frame\n",
    "            threshold (Int)=25: if defined, is the value of the static threshold\n",
    "            C (float)=None: if defined, it will use and adaptive thresholding method and it represent the value of C (Constant subtracted from the mean or weighted mean)\n",
    "            \n",
    "        Returns:\n",
    "            fgmask: binary image with the foreground white (255).\n",
    "    \"\"\"\n",
    "    assert C is not None or threshold is not None, \"Both arguments are None!\"\n",
    "    diff = cv2.absdiff(frame, background)\n",
    "    if C:\n",
    "        block_size = 5\n",
    "        fgmask = cv2.adaptiveThreshold(diff, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, block_size, C)\n",
    "    else:\n",
    "        _, fgmask = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)\n",
    "    return fgmask\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRectangularROI(fgmask):\n",
    "    blur = cv2.GaussianBlur(fgmask, (5,5), 3)\n",
    "    thresh = threshold_otsu(blur)\n",
    "    if thresh == 0:\n",
    "        return False, None\n",
    "    \n",
    "    bw = closing(blur >= thresh, square(7))\n",
    "    #erode = cv2.erode(bw.astype(np.uint8) * 255, None, iterations=3)\n",
    "    #cv2.imshow(\"erode\", erode)\n",
    "    erode = cv2.medianBlur(bw.astype(np.uint8) * 255, 3)\n",
    "    dilated = cv2.dilate(erode, None, iterations=5)\n",
    "    #cv2.imshow(\"dilate\", dilated)        \n",
    "\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    real_countours = []\n",
    "    for contour in contours:\n",
    "        # (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        if cv2.contourArea(contour) > 100:\n",
    "            real_countours.append(contour)\n",
    "        \n",
    "    \n",
    "    if len(real_countours) == 0:\n",
    "        return False, None\n",
    "    \n",
    "    # Define the ROI \n",
    "    x_min = min([np.min(cnt[:, :, 0]) for cnt in real_countours])\n",
    "    x_max = max([np.max(cnt[:, :, 0]) for cnt in real_countours])\n",
    "    y_min = min([np.min(cnt[:, :, 1]) for cnt in real_countours])\n",
    "    y_max = max([np.max(cnt[:, :, 1]) for cnt in real_countours])\n",
    "\n",
    "    return True, (x_min, x_max, y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMTERS\n",
    "FRAME_BUFFERED_PER_SECOND = 2           # 2 images are added to frame buffer each second\n",
    "MAX_HISTORY = fps * 3                   # 3*12 frames are stored in the circual buffer\n",
    "SKIP_FRAMES = fps // FRAME_BUFFERED_PER_SECOND\n",
    "STATIC_THRESHOLD = 30\n",
    "\n",
    "LEARNING_PHASE = 5 * fps              # Initialization phase for the background subtractor to estimate the reference frame\n",
    "\n",
    "start = time.time()\n",
    "frame_buffer = []\n",
    "frame_count = 0\n",
    "skip_count = 0\n",
    "fgmask_diff = None\n",
    "temporalMedianBackground = None\n",
    "initialized = False\n",
    "ratios = []\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame_original = cap.read()\n",
    "    if not ret or frame_original is None:\n",
    "        cap.release()\n",
    "        print(\"Released Video Resource\")\n",
    "        break\n",
    "\n",
    "    frame = preprocessing(frame_original)\n",
    "    frame_count += 1\n",
    "    skip_count += 1\n",
    "\n",
    "    # -------------------------------\n",
    "    # |   TEMPORAL MEDIAN FILTER    |\n",
    "    # -------------------------------\n",
    "    if len(frame_buffer) == 0 or skip_count == SKIP_FRAMES:\n",
    "        skip_count = 0\n",
    "        frame_buffer.append(frame)\n",
    "\n",
    "        if len(frame_buffer) > MAX_HISTORY:\n",
    "            frame_buffer.pop(0)\n",
    "\n",
    "        temporalMedianBackground = np.median(frame_buffer, axis=0).astype(dtype=np.uint8)\n",
    "        temporalMedianBackground_copy = temporalMedianBackground.copy()\n",
    "        cv2.putText(temporalMedianBackground_copy, f\"FRAME: {frame_count}/{total_frame_count}\", (5, 25), font, 0.5, (0, 0, 0), 1) \n",
    "        cv2.imshow(\"temporalMedianBackground\", temporalMedianBackground_copy)\n",
    "\n",
    "    # -------------------------------\n",
    "    # |            MOG2             |\n",
    "    # -------------------------------\n",
    "    mog2_history = mog2.getHistory()\n",
    "    learning_rate = computeLearningRate(frame_count, mog2_history, dynamic=True, bias=0.1)\n",
    "\n",
    "    mog2_fgmask = mog2.apply(frame, learningRate=learning_rate)\n",
    "    mog2_fgmask = postprocessing(mog2_fgmask)\n",
    "    #cv2.imshow(\"Mog2 foreground mask\", mog2_fgmask)\n",
    "    #cv2.imshow(\"Eroded mog2 foreground mask\", dilated)    \n",
    "        \n",
    "    if frame_count > LEARNING_PHASE:\n",
    "        # [ GET A ROI OF THE MOG2 FOREGROUND MASK ]\n",
    "        # frame_contours = frame.copy()\n",
    "        found, roi = getRectangularROI(mog2_fgmask)\n",
    "        # cv2.rectangle(frame_contours, (x_min, y_min), (x_max, y_max), 255, 2)\n",
    "        # cv2.imshow(\"ROI\", frame_contours)\n",
    "\n",
    "        tmb_fgmask = backgroundSubtraction(frame, temporalMedianBackground, threshold=STATIC_THRESHOLD)\n",
    "        \n",
    "        # [ COMBINE FGMSKS IN ROI ]\n",
    "        if found:\n",
    "            combined_fgmask = mog2_fgmask.copy()\n",
    "            x_min, x_max, y_min, y_max = roi\n",
    "            combined_fgmask[y_min:y_max, x_min:x_max] = cv2.bitwise_or(mog2_fgmask[y_min:y_max, x_min:x_max], tmb_fgmask[y_min:y_max, x_min:x_max])    \n",
    "            combined_fgmask = cv2.morphologyEx(combined_fgmask, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "            # cv2.imshow(\"combined_fgmask\", combined_fgmask)\n",
    "\n",
    "            # [ OVERRIDE FROZEN VALUES ]\n",
    "            if fgmask_diff is not None:\n",
    "                tmb_fgmask = cv2.bitwise_or(tmb_fgmask, fgmask_diff)\n",
    "                #tmb_fgmask = cv2.morphologyEx(tmb_fgmask, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "\n",
    "                contours_fg, _ = cv2.findContours(tmb_fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "                cv2.imshow(\"tmb_fgmask\", tmb_fgmask)\n",
    "                \n",
    "                frame_original_contours = cv2.drawContours(frame_original, contours_fg, -1, (0,0,255), cv2.FILLED)\n",
    "                cv2.imshow(\"frame\", frame_original_contours)\n",
    "\n",
    "                # TODO: contours and areas\n",
    "                # ...\n",
    "\n",
    "\n",
    "            # [ STATIC OBJECTS ]\n",
    "            fgmask_diff = cv2.bitwise_and(tmb_fgmask, cv2.bitwise_not(combined_fgmask))\n",
    "            #fgmask_diff = cv2.medianBlur(fgmask_diff, 3)\n",
    "            #fgmask_diff = cv2.dilate(fgmask_diff, None, iterations=3)nnnnn\n",
    "            # cv2.imshow(\"fgmask_diff\", fgmask_diff)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    cmd = cv2.waitKey(0)    \n",
    "    if cmd == ord(\"q\"):\n",
    "        break\n",
    "    if cmd == ord(\"n\"):\n",
    "        continue\n",
    "print(\"Mean Background ratio: \", np.mean(ratios))\n",
    "# valore simile a quelo di default --> lasciamo quello di default\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"[I] Elapsed time: {end - start} s\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
