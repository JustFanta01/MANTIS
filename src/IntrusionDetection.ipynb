{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import closing, square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Video FPS: 12\n",
      "[I] Video Length: 41.916666666666664\n",
      "[I] Video Frame Width: 320\n",
      "[I] Video Frame height: 240\n"
     ]
    }
   ],
   "source": [
    "video_path = \"../video/rilevamento-intrusioni-video.wm\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "assert cap.isOpened(), \"Not opened!\"\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "length = cap.get(cv2.CAP_PROP_FRAME_COUNT) / fps\n",
    "\n",
    "print(f\"[I] Video FPS: {fps}\")\n",
    "print(f\"[I] Video Length: {length}\")\n",
    "\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(f\"[I] Video Frame Width: {width}\")\n",
    "print(f\"[I] Video Frame height: {height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to understand MOG2 parameters\n",
    "\n",
    "# # BackgroundRatio --> ok default (0.9) per ora quindi\n",
    "# If a foreground pixel keeps semi-constant value for about backgroundRatio*history frames, it's considered background and added to the model \n",
    "# as a center of a new component.\n",
    "# \"In altre parole, TB controlla quanto velocemente il modello di sfondo si adatta ai cambiamenti nella scena.\"\n",
    "# - Un valore più alto rende il modello di sfondo più adattabile e meno sensibile ai movimenti.\n",
    "# - Un valore più basso rende il modello di sfondo più stabile e più sensibile ai movimenti, ma anche più lento ad adattarsi.\n",
    "\n",
    "# # VarThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOG2 Background Subtractor\n",
    "mog2 = cv2.createBackgroundSubtractorMOG2()\n",
    "mog2_test = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "mog2.setHistory(fps*6)\n",
    "mog2.setDetectShadows(False)\n",
    "mog2.setVarThreshold(9)\n",
    "mog2.setBackgroundRatio(0.6)\n",
    "\n",
    "mog2_test.setHistory(fps)\n",
    "mog2_test.setDetectShadows(False)\n",
    "mog2_test.setVarThreshold(9)\n",
    "mog2_test.setBackgroundRatio(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#     Performed a sorted insertion of pv into the frame buffer in the pi row.\n",
    "#     pv: pixel value\n",
    "#     pi: pixel index\n",
    "#     frame_buffer (global)\n",
    "# \"\"\"\n",
    "# def sortAndInsert(pv, pi, ):\n",
    "#     global frame_buffer\n",
    "#     insertion_idx = np.searchsorted(frame_buffer[pi], pv)\n",
    "#     if insertion_idx == len(frame_buffer[pi]):\n",
    "#         insertion_idx =- 1\n",
    "\n",
    "#     frame_buffer[pi, insertion_idx] = pv\n",
    "\n",
    "#cv2.imshow(\"frame_copy\", frame_contours)\n",
    "# largestContour = max(contours, key = cv2.contourArea) # get largest contour\n",
    "# rect = cv2.minAreaRect(largestContour)\n",
    "# box = np.int64(cv2.boxPoints(rect))\n",
    "# cv2.drawContours(frame_contours, [box], 0, (0,0,255), 1)\n",
    "# cv2.imshow(\"frame_contours\", frame_contours)\n",
    "\n",
    "# cv2.imshow(f\"temporalMedianBackground-frame-{frame_count}\", temporalMedianBackground)\n",
    "# cmd = cv2.waitKey(0)\n",
    "# cv2.destroyWindow(f\"temporalMedianBackground-frame-{frame_count}\")\n",
    "# if cmd == ord(\"q\"):\n",
    "#     break\n",
    "# if cmd == ord(\"n\"):\n",
    "#     continue\n",
    "\n",
    "# alpha = 3.0 # Contrast control\n",
    "# beta = 25 # Brightness control\n",
    "# # call convertScaleAbs function\n",
    "# #adjusted = cv2.convertScaleAbs(mog2_fgmask, alpha=alpha, beta=beta)\n",
    "\n",
    "\n",
    "# plt.hist(frame_diff.ravel(), 256, [0, 256])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "            \n",
    "# Disegna la bounding box\n",
    "#cv2.rectangle(frame_contours, (x_min, y_min), (x_max, y_max), 255, 2)\n",
    "\n",
    "#cv2.imshow(\"frame_contours\", frame_contours)\n",
    "\n",
    "\n",
    "# analysis = cv2.connectedComponentsWithStats(tmb_fgmask, 8, cv2.CV_32S)\n",
    "# (totalLabels, label_ids, values, centroid) = analysis \n",
    "\n",
    "# # Initialize a new image to store  \n",
    "# # all the output components \n",
    "# output = np.zeros(tmb_fgmask.shape, dtype=\"uint8\") \n",
    "\n",
    "# # Loop through each component \n",
    "# for i in range(1, totalLabels): \n",
    "    \n",
    "#     # Area of the component \n",
    "#     area = values[i, cv2.CC_STAT_AREA]  \n",
    "    \n",
    "#     if (area > 140) and (area < 400): \n",
    "#         componentMask = (label_ids == i).astype(\"uint8\") * 255\n",
    "#         output = cv2.bitwise_or(output, componentMask) \n",
    "\n",
    "# cv2.imshow(\"Filtered Components\", output)\n",
    "# \n",
    "# \n",
    "#mog2 = cv2.createBackgroundSubtractorMOG2(history=fps*2, varThreshold=20, detectShadows=False)\n",
    "\n",
    "# print(mog2.getHistory())\n",
    "# print(mog2.getVarThreshold())\n",
    "# print(mog2.getBackgroundRatio())\n",
    "# print(mog2.getNMixtures())\n",
    "# print(mog2.getVarThresholdGen())\n",
    "# print(mog2.getVarMin())\n",
    "# print(mog2.getVarMax())\n",
    "# print(mog2.getComplexityReductionThreshold())\n",
    "# print(mog2.getVarInit())\n",
    "\n",
    "#mog2.setComplexityReductionThreshold(0)\n",
    "#mog2.setBackgroundRatio(0.7)\n",
    "#mog2.setNMixtures(1)\n",
    "#mog2.setVarThresholdGen(30) \n",
    "\n",
    "#temporalMedianBackground_tmp = np.median(frames_tmp, axis=0).astype(dtype=np.uint8)\n",
    "#cv2.imshow(\"temporal background - true one\", temporalMedianBackground)\n",
    "# make addWeighted between temporalMedianBackground and frame just where the background_mask is 1\n",
    "#masked_img = np.where(background_mask[..., None] == 255, frame[..., None], 0) # dove c'è il background mask metti frame, altrimenti 0\n",
    "#cv2.imshow(\"masked_img\", masked_img)\n",
    "#temporalMedianBackground = cv2.addWeighted(temporalMedianBackground, 0.7, masked_img, 0.3, 0)\n",
    "#temporalMedianBackground = cv2.bitwise_and(temporalMedianBackground, temporalMedianBackground, background_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(frame):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply Median Blur\n",
    "    median = cv2.medianBlur(gray, 5)\n",
    "    gaussian = cv2.GaussianBlur(median, (7, 7), 3)\n",
    "    # Apply Bilateral Filter\n",
    "    filtered = cv2.bilateralFilter(gaussian, 9, 75, 75)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56242/3128952899.py:55: FutureWarning: `square` is deprecated since version 0.25 and will be removed in version 0.27. Use `skimage.morphology.footprint_rectangle` instead.\n",
      "  bw = closing(blur >= thresh, square(7))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Released Video Resource\n",
      "Mean Background ratio:  0.8507272029679042\n",
      "[I] Elapsed time: 24.45100998878479 s\n"
     ]
    }
   ],
   "source": [
    "# HYPERPARAMTERS\n",
    "tuning_history = 6\n",
    "tuning_skip_frame = 4\n",
    "MAX_HISTORY = tuning_history * fps\n",
    "SKIP_FRAMES = fps // tuning_skip_frame\n",
    "THRESHOLD = 30\n",
    "\n",
    "# 320x240 rows, 60 columns\n",
    "# frame_buffer = np.empty((width * height,MAX_HISTORY), dtype=np.uint8)\n",
    "\n",
    "start = time.time()\n",
    "frames = []\n",
    "initialized = False\n",
    "frame_count = 0\n",
    "skip_count = 0\n",
    "fgmask_diff = None\n",
    "temporalMedianBackground = None\n",
    "ratios = []\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame_original = cap.read()\n",
    "    if not ret or frame_original is None:\n",
    "        cap.release()\n",
    "        print(\"Released Video Resource\")\n",
    "        break\n",
    "\n",
    "    frame = preprocessing(frame_original)\n",
    "    #cv2.imshow(\"frame\", frame)\n",
    "    frame_count += 1\n",
    "    skip_count += 1\n",
    "\n",
    "    history = mog2.getHistory()\n",
    "    # history_test = mog2_test.getHistory()\n",
    "    \n",
    "    if frame_count < history:\n",
    "        learning_rate = 1 / frame_count\n",
    "    else:\n",
    "        learning_rate = 1 / history\n",
    "  \n",
    "    learning_rate = learning_rate + 0.1\n",
    "    # learning_rate_test = learning_rate_test + 0.1\n",
    "    mog2_fgmask = mog2.apply(frame, learningRate=learning_rate)\n",
    "    erode = cv2.erode(mog2_fgmask, None, iterations=1)\n",
    "    dilated = cv2.dilate(erode, None, iterations=3)\n",
    "    mog2_fgmask = dilated.copy()\n",
    "    #cv2.imshow(\"Mog2 foreground mask\", mog2_fgmask)\n",
    "    #cv2.imshow(\"Eroded mog2 foreground mask\", dilated)\n",
    "   \n",
    "    # # tentativo\n",
    "    blur = cv2.GaussianBlur(mog2_fgmask, (5,5), 3)\n",
    "    thresh = threshold_otsu(blur)\n",
    "    if thresh > 0:    \n",
    "        bw = closing(blur >= thresh, square(7))\n",
    "        #erode = cv2.erode(bw.astype(np.uint8) * 255, None, iterations=3)\n",
    "        #cv2.imshow(\"erode\", erode)\n",
    "        erode = cv2.medianBlur(bw.astype(np.uint8) * 255, 3)\n",
    "        dilated = cv2.dilate(erode, None, iterations=5)\n",
    "        #cv2.imshow(\"dilate\", dilated)        \n",
    "\n",
    "        frame_contours = frame.copy()\n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        real_countours = []\n",
    "        for contour in contours:\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            \n",
    "            if cv2.contourArea(contour) > 100:\n",
    "                real_countours.append(contour)\n",
    "            \n",
    "        # evitare che impazzisca se non ci sono bboxes\n",
    "        if len(real_countours) > 0:\n",
    "            # Calcola la bounding box\n",
    "            # Define the ROI            \n",
    "            x_min = min([np.min(cnt[:, :, 0]) for cnt in real_countours])\n",
    "            x_max = max([np.max(cnt[:, :, 0]) for cnt in real_countours])\n",
    "            y_min = min([np.min(cnt[:, :, 1]) for cnt in real_countours])\n",
    "            y_max = max([np.max(cnt[:, :, 1]) for cnt in real_countours])\n",
    "\n",
    "            # Disegna la bounding box\n",
    "            #cv2.rectangle(frame_contours, (x_min, y_min), (x_max, y_max), 255, 2)\n",
    "\n",
    "        #cv2.imshow(\"frame_contours\", frame_contours)\n",
    "\n",
    "\n",
    "    if initialized:\n",
    "        # print(f\"[I] Skipping Frames... {skip_count}\")\n",
    "        if skip_count > SKIP_FRAMES:\n",
    "            skip_count = 0\n",
    "            frames.pop(0)\n",
    "            frames.append(frame)\n",
    "            temporalMedianBackground = np.median(frames, axis=0).astype(dtype=np.uint8)\n",
    "            #cv2.imshow(\"temporal background\", temporalMedianBackground)\n",
    "            \n",
    "    if not initialized and len(frames) < MAX_HISTORY:\n",
    "        # print(f\"[I] Learning...\")\n",
    "        frames.append(frame)\n",
    "        \n",
    "    elif not initialized and len(frames) == MAX_HISTORY:\n",
    "        # print(f\"Compute First Estimate\")\n",
    "        # compute the first background estimation\n",
    "        initialized = True    \n",
    "        temporalMedianBackground = np.median(frames, axis=0).astype(dtype=np.uint8)\n",
    "\n",
    "    # Compute the AbsDiff between temporalMedianBackground and the Current Frame\n",
    "    if initialized:\n",
    "        frame_diff = cv2.absdiff(temporalMedianBackground, frame)\n",
    "        threshold, tmb_fgmask = cv2.threshold(frame_diff, THRESHOLD, 255, cv2.THRESH_BINARY)\n",
    "        #cv2.imshow(\"tmb_fgmask\", tmb_fgmask)\n",
    "        \n",
    "        # logical or between mog2 and temporalMedianBackground to create the shape of the fast movement using ROI\n",
    "        fgmask = mog2_fgmask.copy()\n",
    "        fgmask[y_min:y_max, x_min:x_max] = cv2.bitwise_or(mog2_fgmask[y_min:y_max, x_min:x_max], tmb_fgmask[y_min:y_max, x_min:x_max])    \n",
    "        #cv2.imshow(\"Bitwise Mask\", fgmask)\n",
    "    \n",
    "        closing_img = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "        #cv2.imshow(\"closing_img\", closing_img)\n",
    "        \n",
    "        count_white = cv2.countNonZero(closing_img)\n",
    "        total_pixels = width * height\n",
    "        rapp = (total_pixels - count_white) / total_pixels\n",
    "        ratios.append(rapp)\n",
    "        #print(f\"Background ratio: {rapp}\")\n",
    "\n",
    "        #cv2.imshow(\"background mask mog2\", background_mask)\n",
    "\n",
    "        # override frozen values\n",
    "        if fgmask_diff is not None:\n",
    "            tmb_fgmask = cv2.bitwise_or(tmb_fgmask, fgmask_diff)\n",
    "            #tmb_fgmask = cv2.morphologyEx(tmb_fgmask, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "            cv2.imshow(\"tmb_fgmask\", tmb_fgmask)\n",
    "            # TODO: contours and areas\n",
    "\n",
    "        # static objects\n",
    "        fgmask_diff = cv2.bitwise_and(tmb_fgmask, cv2.bitwise_not(closing_img))\n",
    "        #fgmask_diff = cv2.medianBlur(fgmask_diff, 3)\n",
    "        #cv2.imshow(\"fgmask_diff\", fgmask_diff)\n",
    "        #fgmask_diff = cv2.dilate(fgmask_diff, None, iterations=3)\n",
    "\n",
    "        #cv2.imshow(\"fgmask_diff\", fgmask_diff)\n",
    "\n",
    "    cmd = cv2.waitKey(0)    \n",
    "    if cmd == ord(\"q\"):\n",
    "        break\n",
    "    if cmd == ord(\"n\"):\n",
    "        continue\n",
    "print(\"Mean Background ratio: \", np.mean(ratios))\n",
    "# valore simile a quelo di default --> lasciamo quello di default\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"[I] Elapsed time: {end - start} s\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computervision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
