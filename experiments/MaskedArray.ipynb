{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMPORAL MEDIAN FILTER with MASKED ARRAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the very few seconds of the video in which the person is moving right across the same spot over\n",
    "and over, both methods are \"absorbing\" it into the background model.\n",
    "\n",
    "To improve this part we decided to try implementing a **selective update** for the temporal median using the ``numpy.MaskedArray`` module in order to insert in the buffer a ``masked frame`` i.e. a frame and its\n",
    "associated boolean validity mask.\n",
    "\n",
    "If the pixel have been detected as foreground by the algorithm, the validity mask would indicate that the pixel is not valid in the median computation.\n",
    "\n",
    "The results obtained by this approach, on the TemporalMedian foreground mask was qualitative better.\n",
    "The foreground pixels were indeed getting \"absorbed\" less. \n",
    "\n",
    "Let's explore the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import cv2\n",
    "import cv2.version\n",
    "\n",
    "print(f\"cv2.version.opencv_version: {cv2.version.opencv_version}\")\n",
    "print(f\"np.version.full_version: {np.version.full_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.MaskedArray.median method\n",
    "\n",
    "Given a vector ``V`` with ``N`` non masked values, the median of ``V``\n",
    "is the middle value of a sorted copy of ``V`` (``Vs``) - i.e.\n",
    "``Vs[(N-1)/2]``, when ``N`` is odd, or ``{Vs[N/2 - 1] + Vs[N/2]}/2``\n",
    "when ``N`` is even.\n",
    "\n",
    "String used in lieu of missing data when a masked array is printed. By default, this string is ``'--'``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median: --\n",
      "median: 0\n",
      "median: 10.0\n",
      "median: 10\n",
      "median: 12.5\n",
      "median: 12\n"
     ]
    }
   ],
   "source": [
    "not_valid = ma.array(   data = [    1, 2, 2, 5, 10, 15, 25, 40], \n",
    "                        mask = [    1, 1, 1, 1,  1,  1,  1,  1])\n",
    "print(f\"median: {ma.median(not_valid)}\")\n",
    "print(f\"median: {ma.median(not_valid).astype(np.uint8)}\")\n",
    "\n",
    "good = ma.array(data = [    1, 2, 2, 5, 10, 15, 25, 40], \n",
    "                mask = [    1, 0, 1, 1,  0,  1,  1,  0])\n",
    "print(f\"median: {ma.median(good)}\")\n",
    "print(f\"median: {ma.median(good).astype(np.uint8)}\")\n",
    "\n",
    "good_2d = ma.array(data = [     [1, 2, 2],\n",
    "                                [5, 10, 15], \n",
    "                                [25, 40, 50]], \n",
    "                mask = [[1, 1, 0], \n",
    "                        [1, 0, 0],\n",
    "                        [1, 1, 0]])\n",
    "print(f\"median: {ma.median(good_2d)}\")\n",
    "print(f\"median: {ma.median(good_2d).astype(np.uint8)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Median with Selective Update\n",
    "This code part was developed only to understand how to use and implement the selective update for the temporal median background model. <br>\n",
    "**Note:** It does *not* follow the code structure presente in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_video(path):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    assert cap.isOpened(), \"Not opened!\"\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    length = total_frame_count / fps\n",
    "\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    print(f\"[I] Video FPS: {fps}\")\n",
    "    print(f\"[I] Video Total frame count: {total_frame_count}\")\n",
    "    print(f\"[I] Video Length: {length}\")\n",
    "    print(f\"[I] Video Frame Width: {width}\")\n",
    "    print(f\"[I] Video Frame height: {height}\")\n",
    "    return cap, fps, total_frame_count, (width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap, fps, total_frame_count, (width, height) = open_video(\"../video/rilevamento-intrusioni-video.wm\")\n",
    "\n",
    "FRAME_BUFFERED_PER_SECOND = 2                  # 2 images added each second to frame buffer\n",
    "MAX_HISTORY = fps                              # 12 frames stored in the \"circular buffer\"\n",
    "SKIP_FRAMES = fps // FRAME_BUFFERED_PER_SECOND\n",
    "\n",
    "frame_count = 0\n",
    "skip_count = 0\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "stacked = np.ma.masked_all((MAX_HISTORY, height, width))\n",
    "n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first 5 seconds of frames by using 2 frames per second\n",
    "frameIds = range(0, int(cap.get(cv2.CAP_PROP_FPS) * 5), SKIP_FRAMES)\n",
    " \n",
    "# Store selected frames in an array\n",
    "frames_5sec = []\n",
    "for fid in frameIds:\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, fid)\n",
    "    ret, frame = cap.read()\n",
    "    # frame = cv2.GaussianBlur(frame, (3, 3), 3)\n",
    "    frames_5sec.append(frame)\n",
    "\n",
    "# Calculate the median along the time axis\n",
    "medianFrame = np.median(frames_5sec, axis=0).astype(dtype=np.uint8)\n",
    "medianFrame = cv2.cvtColor(medianFrame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_frame = None\n",
    "temporalMedianBackground = None\n",
    "oldTemporalMedianBackground = None\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame_original = cap.read()\n",
    "    if not ret or frame_original is None:\n",
    "        cap.release()\n",
    "        print(\"Released Video Resource\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    skip_count += 1\n",
    "    \n",
    "    frame = cv2.cvtColor(frame_original, cv2.COLOR_BGR2GRAY)\n",
    "    if n > 0:\n",
    "        diff = cv2.absdiff(frame, temporalMedianBackground)\n",
    "        # [ DETECT FOREGROUND ]\n",
    "        _, binary = cv2.threshold(diff, 35, 255, cv2.THRESH_BINARY)\n",
    "        binary = cv2.erode(binary, np.ones((3,3), np.uint8))\n",
    "        binary = cv2.dilate(binary, np.ones((3,3), np.uint8), iterations=4)\n",
    "        binary = cv2.erode(binary, np.ones((3,3), np.uint8))\n",
    "        binary = cv2.dilate(binary, np.ones((3,3), np.uint8), iterations=1)\n",
    "\n",
    "        # [ DO NOT USE FOREGROUND IN THE TEMPORAL MEDIAN ]\n",
    "        masked_frame = ma.masked_where(binary == 255, frame)\n",
    "        \n",
    "        cv2.imshow(\"mask\", binary)\n",
    "\n",
    "\n",
    "    if len(stacked) == 0 or skip_count == SKIP_FRAMES:\n",
    "        skip_count = 0\n",
    "        stacked[n] = masked_frame if masked_frame is not None else ma.masked_array(medianFrame)\n",
    "        n+=1\n",
    "        if n == MAX_HISTORY:\n",
    "            n = 0\n",
    "\n",
    "        temporalMedianBackground = ma.median(stacked, axis=0)\n",
    "        if oldTemporalMedianBackground is not None:\n",
    "            missing_mask = temporalMedianBackground.mask == True\n",
    "\n",
    "            # The mask of a masked array is accessible through its mask attribute.\n",
    "            # We must keep in mind that a True entry in the mask indicates an invalid data.\n",
    "            missing_mask_copy = missing_mask.copy()\n",
    "            missing_mask_copy = missing_mask_copy.astype(dtype='uint8')\n",
    "            missing_mask_copy *= 255\n",
    "            cv2.imshow(\"missing_mask\", missing_mask_copy)\n",
    "            \n",
    "            # If all the values int he buffer are invalid for that position, keep the old one.\n",
    "            # For this reason in this implementation we estimated the median frame to have a reasonable init value.\n",
    "            temporalMedianBackground[missing_mask] = oldTemporalMedianBackground[missing_mask]\n",
    "            \n",
    "            # the values are now valid, empty the mask\n",
    "            temporalMedianBackground.mask = np.zeros_like(temporalMedianBackground.mask)\n",
    "        \n",
    "        temporalMedianBackground = temporalMedianBackground.astype(dtype=np.uint8)\n",
    "        oldTemporalMedianBackground = temporalMedianBackground\n",
    "        temporalMedianBackground_copy = temporalMedianBackground.copy()\n",
    "        cv2.putText(temporalMedianBackground_copy, f\"FRAME: {frame_count}/{total_frame_count}\", (5, 25), font, 0.5, (0, 0, 0), 1) \n",
    "        cv2.imshow(\"temporalMedianBackground\", temporalMedianBackground_copy)\n",
    "    \n",
    "    cmd = cv2.waitKey(0)\n",
    "    if cmd == ord(\"q\"):\n",
    "        break\n",
    "    if cmd == ord(\"n\"):\n",
    "        continue\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main problem were:\n",
    "1. higher computational time\n",
    "2. due to combination with `MOG2`, the problem was only half solved.\n",
    "\n",
    "The increased computation time was causing the algorithm to slow down. Even after reducing the buffer size —a reasonable adjustment since, in theory, the buffer should now contain only valid values— the issue persisted.\n",
    "\n",
    "Another issue arises from the combination of masks performed in `Step [4]` and the fact that in the `MOG2` method, pixels are quickly \"absorbed\".\n",
    "\n",
    "Given a quasi static object, over time, the `MOG2` method produces a \"fading\" foreground mask; the longer an object remains still, the more the foreground mask diminishes. On the other hand, the `temporalMedian` could, in theory, still perceive the difference in the \"static\" phase of the object.\n",
    "\n",
    "However, due to the fact that `MOG2`, our short time horizon algorithm, dictates the ROI in which the combination of the foreground masks happens, a quasi static object wouldn't result in the `combined foreground mask`, even if the `TemporalMedian` is correctingly detecting it.\n",
    "\n",
    "Finally, when the person starts moving again and change its position rapidly, as seen in a few frames of the video, the `MOG2` method will create a \"ghost\" effect, duplicating the figure.\n",
    "\n",
    "For these reasons, <ins>**we decided against incorporating this part**.</ins>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
